{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52549f78",
   "metadata": {},
   "source": [
    "Static word embeddings with Glove and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f98833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,GRU\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f31f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3134b60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline\n",
       "0             1  thirtysomething scientists unveil doomsday clo...\n",
       "1             0  dem rep. totally nails why congress is falling...\n",
       "2             0  eat your veggies: 9 deliciously different recipes\n",
       "3             1  inclement weather prevents liar from getting t...\n",
       "4             1  mother comes pretty close to using word 'strea..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['article_link']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e836f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wangj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f95ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\wangj\\AppData\\Local\\Temp\\ipykernel_24500\\1508946720.py:7: SyntaxWarning: invalid escape sequence '\\['\n",
      "  return re.sub('\\[[^]]*\\]', '', text)\n",
      "C:\\Users\\wangj\\AppData\\Local\\Temp\\ipykernel_24500\\1508946720.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['headline']=df['headline'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae53aea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\users\\wangj\\appdata\\roaming\\python\\python312\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\wangj\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\wangj\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\wangj\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\wangj\\appdata\\roaming\\python\\python312\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3976f1",
   "metadata": {},
   "source": [
    "Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9f21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "words = []\n",
    "for i in df.headline.values:\n",
    "    words.append(i.split())\n",
    "#Dimension of vectors we are generating\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "w2v_model = gensim.models.Word2Vec(sentences = words , vector_size=EMBEDDING_DIM , window = 5 , min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a19e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=35000)\n",
    "tokenizer.fit_on_texts(words)\n",
    "tokenized_train = tokenizer.texts_to_sequences(words)\n",
    "x = sequence.pad_sequences(tokenized_train, maxlen = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa81b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c71beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create weight matrix from word2vec gensim model\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        if word in model.wv:\n",
    "            weight_matrix[i] = model.wv[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82f480e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2434c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Network\n",
    "model = Sequential()\n",
    "#Non-trainable embeddidng layer\n",
    "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=20, trainable=True))\n",
    "#LSTM \n",
    "model.add(Bidirectional(LSTM(units=128 , recurrent_dropout = 0.3 , dropout = 0.3,return_sequences = True)))\n",
    "model.add(Bidirectional(GRU(units=32 , recurrent_dropout = 0.1 , dropout = 0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.01), loss='binary_crossentropy', metrics=[tf.keras.metrics.F1Score(dtype=tf.float32)], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3402e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, df.is_sarcastic.values.astype('float32') , test_size = 0.3 , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624a031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 265s 2s/step - loss: 0.5182 - f1_score: 0.6483 - val_loss: 0.4209 - val_f1_score: 0.6384\n",
      "Epoch 2/3\n",
      "157/157 [==============================] - 265s 2s/step - loss: 0.5182 - f1_score: 0.6483 - val_loss: 0.4209 - val_f1_score: 0.6384\n",
      "Epoch 2/3\n",
      "157/157 [==============================] - 262s 2s/step - loss: 0.1473 - f1_score: 0.6483 - val_loss: 0.5300 - val_f1_score: 0.6384\n",
      "Epoch 3/3\n",
      "157/157 [==============================] - 262s 2s/step - loss: 0.1473 - f1_score: 0.6483 - val_loss: 0.5300 - val_f1_score: 0.6384\n",
      "Epoch 3/3\n",
      "157/157 [==============================] - 262s 2s/step - loss: 0.0387 - f1_score: 0.6483 - val_loss: 0.7769 - val_f1_score: 0.6384\n",
      "157/157 [==============================] - 262s 2s/step - loss: 0.0387 - f1_score: 0.6483 - val_loss: 0.7769 - val_f1_score: 0.6384\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 128 , validation_data = (x_test,y_test) , epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2edd18c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 128s 478ms/step\n",
      "269/269 [==============================] - 128s 478ms/step\n",
      "Accuracy:  0.7879\n",
      "Precision: 0.7662\n",
      "Recall:    0.7881\n",
      "F1-Score:  0.7770\n",
      "\n",
      "Classification Report:\n",
      "Accuracy:  0.7879\n",
      "Precision: 0.7662\n",
      "Recall:    0.7881\n",
      "F1-Score:  0.7770\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Sarcastic       0.81      0.79      0.80      4560\n",
      "    Sarcastic       0.77      0.79      0.78      4026\n",
      "\n",
      "     accuracy                           0.79      8586\n",
      "    macro avg       0.79      0.79      0.79      8586\n",
      " weighted avg       0.79      0.79      0.79      8586\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Sarcastic       0.81      0.79      0.80      4560\n",
      "    Sarcastic       0.77      0.79      0.78      4026\n",
      "\n",
      "     accuracy                           0.79      8586\n",
      "    macro avg       0.79      0.79      0.79      8586\n",
      " weighted avg       0.79      0.79      0.79      8586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "y_pred_prob = model.predict(x_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Also print classification report for detailed metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Sarcastic', 'Sarcastic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bd56a",
   "metadata": {},
   "source": [
    "Glove:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a496361",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df.headline,df.is_sarcastic, test_size = 0.3 , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59e7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 35000\n",
    "maxlen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f8fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167d7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "X_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3acd62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'data/glove.twitter.27B.25d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d4c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1542d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = np.stack(list(embeddings_index.values()))\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = len(word_index) + 1  # +1 for padding token at index 0\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c90882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 2\n",
    "embed_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88e49839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Non-trainable embeddidng layer\n",
    "model.add(Embedding(nb_words, output_dim=embed_size, weights=[embedding_matrix], input_length=200, trainable=True))\n",
    "#LSTM \n",
    "model.add(Bidirectional(LSTM(units=128 , recurrent_dropout = 0.5 , dropout = 0.5)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.01), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9eee2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "157/157 [==============================] - 78s 469ms/step - loss: 0.5625 - acc: 0.7082 - val_loss: 0.4669 - val_acc: 0.7838\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 78s 469ms/step - loss: 0.5625 - acc: 0.7082 - val_loss: 0.4669 - val_acc: 0.7838\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 75s 475ms/step - loss: 0.3359 - acc: 0.8555 - val_loss: 0.3996 - val_acc: 0.8280\n",
      "157/157 [==============================] - 75s 475ms/step - loss: 0.3359 - acc: 0.8555 - val_loss: 0.3996 - val_acc: 0.8280\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "388890cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 8s 30ms/step\n",
      "269/269 [==============================] - 8s 30ms/step\n",
      "Accuracy:  0.8280\n",
      "Precision: 0.8719\n",
      "Recall:    0.7422\n",
      "F1-Score:  0.8018\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Sarcastic       0.80      0.90      0.85      4560\n",
      "    Sarcastic       0.87      0.74      0.80      4026\n",
      "\n",
      "     accuracy                           0.83      8586\n",
      "    macro avg       0.84      0.82      0.82      8586\n",
      " weighted avg       0.83      0.83      0.83      8586\n",
      "\n",
      "Accuracy:  0.8280\n",
      "Precision: 0.8719\n",
      "Recall:    0.7422\n",
      "F1-Score:  0.8018\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Sarcastic       0.80      0.90      0.85      4560\n",
      "    Sarcastic       0.87      0.74      0.80      4026\n",
      "\n",
      "     accuracy                           0.83      8586\n",
      "    macro avg       0.84      0.82      0.82      8586\n",
      " weighted avg       0.83      0.83      0.83      8586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Also print classification report for detailed metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Sarcastic', 'Sarcastic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383baf3a",
   "metadata": {},
   "source": [
    "LLM Finetune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dbeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e1068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install typing_extensions>=4.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77e9f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f13fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Choose model (you can change to 'roberta-base' if preferred)\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data - split the original dataframe\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['headline'].tolist(), \n",
    "    df['is_sarcastic'].tolist(), \n",
    "    test_size=0.3, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# The code below was generated by AI; see [1].\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
    "test_dataset = Dataset.from_dict({'text': test_texts, 'label': test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81180a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe00e9420b2452bac8ffd71a5843d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724d9b8947b44eec8b830deae6b8d3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8586 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34088479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below was generated by AI; see [2].\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True, \n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6798250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7ceb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangj\\AppData\\Roaming\\Python\\Python312\\site-packages\\accelerate\\accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057068a5e4304c5abcbf50e4c09df463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5609, 'grad_norm': 6.999548435211182, 'learning_rate': 1.936842105263158e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4531, 'grad_norm': 6.616657733917236, 'learning_rate': 1.8730462519936205e-05, 'epoch': 0.32}\n",
      "{'loss': 0.4531, 'grad_norm': 6.616657733917236, 'learning_rate': 1.8730462519936205e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3792, 'grad_norm': 6.039819240570068, 'learning_rate': 1.8092503987240832e-05, 'epoch': 0.48}\n",
      "{'loss': 0.3792, 'grad_norm': 6.039819240570068, 'learning_rate': 1.8092503987240832e-05, 'epoch': 0.48}\n",
      "{'loss': 0.3654, 'grad_norm': 5.852889537811279, 'learning_rate': 1.7454545454545456e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3654, 'grad_norm': 5.852889537811279, 'learning_rate': 1.7454545454545456e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3591, 'grad_norm': 7.357544422149658, 'learning_rate': 1.6816586921850083e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3591, 'grad_norm': 7.357544422149658, 'learning_rate': 1.6816586921850083e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3133, 'grad_norm': 4.97999382019043, 'learning_rate': 1.6178628389154706e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3133, 'grad_norm': 4.97999382019043, 'learning_rate': 1.6178628389154706e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cbcdc72e934188b25664c6fe78f0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3031638264656067, 'eval_accuracy': 0.8725832750989984, 'eval_f1': 0.8706550011823126, 'eval_precision': 0.8307761732851986, 'eval_recall': 0.914555389965226, 'eval_runtime': 10.476, 'eval_samples_per_second': 819.589, 'eval_steps_per_second': 25.678, 'epoch': 1.0}\n",
      "{'loss': 0.2559, 'grad_norm': 10.363936424255371, 'learning_rate': 1.5540669856459333e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2559, 'grad_norm': 10.363936424255371, 'learning_rate': 1.5540669856459333e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2281, 'grad_norm': 10.028306007385254, 'learning_rate': 1.4902711323763957e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2281, 'grad_norm': 10.028306007385254, 'learning_rate': 1.4902711323763957e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2391, 'grad_norm': 11.0701265335083, 'learning_rate': 1.426475279106858e-05, 'epoch': 1.44}\n",
      "{'loss': 0.2391, 'grad_norm': 11.0701265335083, 'learning_rate': 1.426475279106858e-05, 'epoch': 1.44}\n",
      "{'loss': 0.2127, 'grad_norm': 5.7563958168029785, 'learning_rate': 1.3626794258373206e-05, 'epoch': 1.59}\n",
      "{'loss': 0.2127, 'grad_norm': 5.7563958168029785, 'learning_rate': 1.3626794258373206e-05, 'epoch': 1.59}\n",
      "{'loss': 0.2036, 'grad_norm': 6.361117839813232, 'learning_rate': 1.2995215311004786e-05, 'epoch': 1.75}\n",
      "{'loss': 0.2036, 'grad_norm': 6.361117839813232, 'learning_rate': 1.2995215311004786e-05, 'epoch': 1.75}\n",
      "{'loss': 0.2078, 'grad_norm': 4.64809513092041, 'learning_rate': 1.235725677830941e-05, 'epoch': 1.91}\n",
      "{'loss': 0.2078, 'grad_norm': 4.64809513092041, 'learning_rate': 1.235725677830941e-05, 'epoch': 1.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3d76f191114113854f725d3a1d0bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3099174499511719, 'eval_accuracy': 0.8830654553924994, 'eval_f1': 0.8688267572511106, 'eval_precision': 0.9164829106945975, 'eval_recall': 0.8258817685047193, 'eval_runtime': 9.8332, 'eval_samples_per_second': 873.164, 'eval_steps_per_second': 27.356, 'epoch': 2.0}\n",
      "{'loss': 0.1409, 'grad_norm': 5.272627830505371, 'learning_rate': 1.1719298245614036e-05, 'epoch': 2.07}\n",
      "{'loss': 0.1409, 'grad_norm': 5.272627830505371, 'learning_rate': 1.1719298245614036e-05, 'epoch': 2.07}\n",
      "{'loss': 0.1115, 'grad_norm': 14.233396530151367, 'learning_rate': 1.1081339712918662e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1115, 'grad_norm': 14.233396530151367, 'learning_rate': 1.1081339712918662e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1045, 'grad_norm': 22.700342178344727, 'learning_rate': 1.0443381180223287e-05, 'epoch': 2.39}\n",
      "{'loss': 0.1045, 'grad_norm': 22.700342178344727, 'learning_rate': 1.0443381180223287e-05, 'epoch': 2.39}\n",
      "{'loss': 0.1139, 'grad_norm': 17.321901321411133, 'learning_rate': 9.80542264752791e-06, 'epoch': 2.55}\n",
      "{'loss': 0.1139, 'grad_norm': 17.321901321411133, 'learning_rate': 9.80542264752791e-06, 'epoch': 2.55}\n",
      "{'loss': 0.112, 'grad_norm': 20.084217071533203, 'learning_rate': 9.167464114832538e-06, 'epoch': 2.71}\n",
      "{'loss': 0.112, 'grad_norm': 20.084217071533203, 'learning_rate': 9.167464114832538e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1367, 'grad_norm': 14.44986343383789, 'learning_rate': 8.529505582137161e-06, 'epoch': 2.87}\n",
      "{'loss': 0.1367, 'grad_norm': 14.44986343383789, 'learning_rate': 8.529505582137161e-06, 'epoch': 2.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1194baa7a99d49fc9170836c607b5b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3679862320423126, 'eval_accuracy': 0.8918006056370836, 'eval_f1': 0.8851242735254111, 'eval_precision': 0.881310022162029, 'eval_recall': 0.8889716840536512, 'eval_runtime': 9.8133, 'eval_samples_per_second': 874.932, 'eval_steps_per_second': 27.412, 'epoch': 3.0}\n",
      "{'loss': 0.0972, 'grad_norm': 2.5403761863708496, 'learning_rate': 7.891547049441787e-06, 'epoch': 3.03}\n",
      "{'loss': 0.0972, 'grad_norm': 2.5403761863708496, 'learning_rate': 7.891547049441787e-06, 'epoch': 3.03}\n",
      "{'loss': 0.068, 'grad_norm': 4.1366777420043945, 'learning_rate': 7.253588516746413e-06, 'epoch': 3.19}\n",
      "{'loss': 0.068, 'grad_norm': 4.1366777420043945, 'learning_rate': 7.253588516746413e-06, 'epoch': 3.19}\n",
      "{'loss': 0.0511, 'grad_norm': 8.440685272216797, 'learning_rate': 6.615629984051037e-06, 'epoch': 3.35}\n",
      "{'loss': 0.0511, 'grad_norm': 8.440685272216797, 'learning_rate': 6.615629984051037e-06, 'epoch': 3.35}\n",
      "{'loss': 0.0588, 'grad_norm': 8.935513496398926, 'learning_rate': 5.977671451355662e-06, 'epoch': 3.51}\n",
      "{'loss': 0.0588, 'grad_norm': 8.935513496398926, 'learning_rate': 5.977671451355662e-06, 'epoch': 3.51}\n",
      "{'loss': 0.0784, 'grad_norm': 1.7974737882614136, 'learning_rate': 5.339712918660288e-06, 'epoch': 3.67}\n",
      "{'loss': 0.0784, 'grad_norm': 1.7974737882614136, 'learning_rate': 5.339712918660288e-06, 'epoch': 3.67}\n",
      "{'loss': 0.0681, 'grad_norm': 15.425726890563965, 'learning_rate': 4.7017543859649125e-06, 'epoch': 3.83}\n",
      "{'loss': 0.0681, 'grad_norm': 15.425726890563965, 'learning_rate': 4.7017543859649125e-06, 'epoch': 3.83}\n",
      "{'loss': 0.0537, 'grad_norm': 7.700492858886719, 'learning_rate': 4.063795853269538e-06, 'epoch': 3.99}\n",
      "{'loss': 0.0537, 'grad_norm': 7.700492858886719, 'learning_rate': 4.063795853269538e-06, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd01141c6f247dc9ed972cdbe0676f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4996281862258911, 'eval_accuracy': 0.8895877009084556, 'eval_f1': 0.8790199081163859, 'eval_precision': 0.9039370078740158, 'eval_recall': 0.8554396423248882, 'eval_runtime': 9.7773, 'eval_samples_per_second': 878.157, 'eval_steps_per_second': 27.513, 'epoch': 4.0}\n",
      "{'loss': 0.0267, 'grad_norm': 12.466241836547852, 'learning_rate': 3.425837320574163e-06, 'epoch': 4.15}\n",
      "{'loss': 0.0267, 'grad_norm': 12.466241836547852, 'learning_rate': 3.425837320574163e-06, 'epoch': 4.15}\n",
      "{'loss': 0.0422, 'grad_norm': 1.8953601121902466, 'learning_rate': 2.7878787878787885e-06, 'epoch': 4.31}\n",
      "{'loss': 0.0422, 'grad_norm': 1.8953601121902466, 'learning_rate': 2.7878787878787885e-06, 'epoch': 4.31}\n",
      "{'loss': 0.0337, 'grad_norm': 0.033049944788217545, 'learning_rate': 2.1499202551834134e-06, 'epoch': 4.47}\n",
      "{'loss': 0.0337, 'grad_norm': 0.033049944788217545, 'learning_rate': 2.1499202551834134e-06, 'epoch': 4.47}\n",
      "{'loss': 0.0293, 'grad_norm': 0.17403681576251984, 'learning_rate': 1.5119617224880383e-06, 'epoch': 4.63}\n",
      "{'loss': 0.0293, 'grad_norm': 0.17403681576251984, 'learning_rate': 1.5119617224880383e-06, 'epoch': 4.63}\n",
      "{'loss': 0.0454, 'grad_norm': 21.888357162475586, 'learning_rate': 8.740031897926636e-07, 'epoch': 4.78}\n",
      "{'loss': 0.0454, 'grad_norm': 21.888357162475586, 'learning_rate': 8.740031897926636e-07, 'epoch': 4.78}\n",
      "{'loss': 0.0403, 'grad_norm': 24.602750778198242, 'learning_rate': 2.4242424242424244e-07, 'epoch': 4.94}\n",
      "{'loss': 0.0403, 'grad_norm': 24.602750778198242, 'learning_rate': 2.4242424242424244e-07, 'epoch': 4.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97f02b1e54f4d6cbc596d01e4b0d6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5370590090751648, 'eval_accuracy': 0.8916841369671559, 'eval_f1': 0.8830188679245283, 'eval_precision': 0.8944954128440367, 'eval_recall': 0.8718330849478391, 'eval_runtime': 9.7865, 'eval_samples_per_second': 877.327, 'eval_steps_per_second': 27.487, 'epoch': 5.0}\n",
      "{'train_runtime': 544.6081, 'train_samples_per_second': 183.921, 'train_steps_per_second': 5.756, 'train_loss': 0.16601591653991163, 'epoch': 5.0}\n",
      "{'train_runtime': 544.6081, 'train_samples_per_second': 183.921, 'train_steps_per_second': 5.756, 'train_loss': 0.16601591653991163, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3135, training_loss=0.16601591653991163, metrics={'train_runtime': 544.6081, 'train_samples_per_second': 183.921, 'train_steps_per_second': 5.756, 'total_flos': 6588629715033600.0, 'train_loss': 0.16601591653991163, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea48038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5494840d0e64e9983a69cf4c7660c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Accuracy:  0.8918\n",
      "Precision: 0.8813\n",
      "Recall:    0.8890\n",
      "F1-Score:  0.8851\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Accuracy:  {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"Recall:    {eval_results['eval_recall']:.4f}\")\n",
    "print(f\"F1-Score:  {eval_results['eval_f1']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
